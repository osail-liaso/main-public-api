let defaultModels = [
  {
    name: { en: "GPT-4", fr: "GPT-4" },
    model: "gpt-4-1106-preview",
    provider: "openAi",
    contextLimit: 128000,
    maxOutput: 4096,
    concurrentInstances: 20,
    costPer1mOutput: 10,
    costPer1mInput: 30,
    image: { input: true, output: false },
  },
  {
    name: { en: "GPT-4o", fr: "GPT-4o" },
    model: "gpt-4o",
    provider: "openAi",
    contextLimit: 128000,
    maxOutput: 4096,
    concurrentInstances: 20,
    costPer1mOutput: 5,
    costPer1mInput: 15,
    image: { input: true, output: false },
  },
  {
    name: { en: "GPT-4o mini", fr: "GPT-4o mini" },
    model: "gpt-4o-mini",
    provider: "openAi",
    contextLimit: 128000,
    maxOutput: 4096,
    concurrentInstances: 20,
    costPer1mOutput: 0.15,
    costPer1mInput: 0.6,
    image: { input: true, output: false },
  },

  {
    name: { en: "Claude Sonnet 3.5", fr: "Claude Sonnet 3.5" },
    model: "claude-3-5-sonnet-20240620",
    provider: "anthropic",
    contextLimit: 200000,
    maxOutput: 8192,
    concurrentInstances: 5,
    costPer1mOutput: 3,
    costPer1mInput: 15,
    image: { input: true, output: false },
  },
  {
    name: { en: "Mistral Large 2", fr: "Mistral Large 2" },
    model: "mistral-large-latest",
    provider: "mistral",
    contextLimit: 128000,
    maxOutput: 4096,
    concurrentInstances: 5,
    costPer1mOutput: 3,
    costPer1mInput: 9,
  },
  {
    name: { en: "Mixtral 8x22B", fr: "Mixtral 8x22B" },
    model: "open-mixtral-8x22b",
    provider: "mistral",
    contextLimit: 64000,
    maxOutput: 4096,
    concurrentInstances: 5,
    costPer1mOutput: 2,
    costPer1mInput: 6,
    image: { input: true, output: false },
    audio: { input: true, output: false },
    video: { input: true, output: false },
  },
  {
    name: { en: "Meta Llama 3.1 70B", fr: "Meta Llama 3.1 70B" },
    model: "llama-3.1-70b-versatile",
    provider: "groq",
    contextLimit: 131072,
    maxOutput: 4096,
    concurrentInstances: 1,
    costPer1mOutput: 0,
    costPer1mInput: 0,
  },
  {
    name: { en: "Google Gemma 2 9B", fr: "Google Gemma 2 9B" },
    model: "gemma2-9b-it",
    provider: "groq",
    contextLimit: 8192,
    maxOutput: 4096,
    concurrentInstances: 1,
    costPer1mOutput: 0,
    costPer1mInput: 0,
  },
];

module.exports = { defaultModels };
